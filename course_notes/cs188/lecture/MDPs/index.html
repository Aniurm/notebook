
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../Search-with-Other-Agents/">
      
      
        <link rel="next" href="../RL/">
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.34">
    
    
      
        <title>Markov Decision Processes - Aniurm's Notebook</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.35f28582.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Mono:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto Mono";--md-code-font:"JetBrains Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../css/extra.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#markov-decision-processes" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="Aniurm&#39;s Notebook" class="md-header__button md-logo" aria-label="Aniurm's Notebook" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Aniurm's Notebook
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Markov Decision Processes
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="Aniurm&#39;s Notebook" class="md-nav__button md-logo" aria-label="Aniurm's Notebook" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Aniurm's Notebook
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    课程笔记
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            课程笔记
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    MIT6.S081
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            MIT6.S081
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1_1" id="__nav_2_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Labs
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_1">
            <span class="md-nav__icon md-icon"></span>
            Labs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../mitos/lab/trap/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    traps
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../mitos/lab/lazy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    xv6 lazy page allocation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../mitos/lab/cow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Copy-on-Write Fork
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../mitos/lab/thread/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multithreading
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../mitos/lab/locks/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    locks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../mitos/lab/fs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    file system
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../mitos/lab/mmap/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mmap
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    CMU15-445/645
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            CMU15-445/645
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cmu15445/primer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    C++ PRIMER
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cmu15445/buffer-pool/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BUFFER POOL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cmu15445/hash-index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    EXTENDIBLE HASH INDEX
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    集成电路
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            集成电路
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ic/mos-physic/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MOS器件物理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ic/mos-small-signal/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MOS小信号模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ic/single-stage-amp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single Stage Amplifiers
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4" >
        
          
          <label class="md-nav__link" for="__nav_2_4" id="__nav_2_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    深度学习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4">
            <span class="md-nav__icon md-icon"></span>
            深度学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../deep-learning/lrnn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Logistic Regression as a Neural Network
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../deep-learning/cnn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Convolutional Neural Networks
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_5" >
        
          
          <label class="md-nav__link" for="__nav_2_5" id="__nav_2_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    CS144
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_5">
            <span class="md-nav__icon md-icon"></span>
            CS144
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs144/lab0/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Lab 0: networking warmup
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs144/lab1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Lab 1: stitching substrings into a byte stream
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs144/lab2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Lab 2: the TCP receiver
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs144/lab3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Lab3: the TCP sender
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_6" checked>
        
          
          <label class="md-nav__link" for="__nav_2_6" id="__nav_2_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    CS188
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_6">
            <span class="md-nav__icon md-icon"></span>
            CS188
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_6_1" checked>
        
          
          <label class="md-nav__link" for="__nav_2_6_1" id="__nav_2_6_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Lecture
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_6_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_6_1">
            <span class="md-nav__icon md-icon"></span>
            Lecture
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Intro-to-AI/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Intro to AI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Uninformed-Search/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Uninformed Search
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Informed-Search/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Informed Search
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../CSPs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Constraint Satisfaction Problems
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Search-with-Other-Agents/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Search with Other Agents
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Markov Decision Processes
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Markov Decision Processes
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#non-deterministic-search" class="md-nav__link">
    <span class="md-ellipsis">
      Non-Deterministic Search
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#markov-decision-processes_1" class="md-nav__link">
    <span class="md-ellipsis">
      Markov Decision Processes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Markov Decision Processes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#finite-horizons-and-discounting" class="md-nav__link">
    <span class="md-ellipsis">
      Finite Horizons and Discounting
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#markovianess" class="md-nav__link">
    <span class="md-ellipsis">
      Markovianess
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#solving-markov-decision-processes" class="md-nav__link">
    <span class="md-ellipsis">
      Solving Markov Decision Processes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Solving Markov Decision Processes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-bellman-equation" class="md-nav__link">
    <span class="md-ellipsis">
      The Bellman Equation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#value-iteration" class="md-nav__link">
    <span class="md-ellipsis">
      Value Iteration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#policy-extraction" class="md-nav__link">
    <span class="md-ellipsis">
      Policy Extraction
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#q-value-iteration" class="md-nav__link">
    <span class="md-ellipsis">
      Q-Value Iteration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#policy-iteration" class="md-nav__link">
    <span class="md-ellipsis">
      Policy Iteration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../RL/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reinforcement Learning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Probability/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Probability
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../BN-representation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BN: Representation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../BN-Independence/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BN: Independence
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../BN-Inference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BN: Inference
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../BN-Sampling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BN: Sampling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Decision%20Networks%20%26%20VPI/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Decision Networks &amp; VPI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Hidden%20Markov%20Models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hidden Markov Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Particle%20Filtering/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Particle Filtering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ML-Naive%20Bayes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ML: Naive Bayes
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ML-Perceptrons/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ML: Perceptrons
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ML-Logistic-Regression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ML: Logistic Regression
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ML-Optimization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ML: Optimization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ML-Neural-Networks/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ML: Neural Networks
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_6_2" >
        
          
          <label class="md-nav__link" for="__nav_2_6_2" id="__nav_2_6_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Project
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_6_2">
            <span class="md-nav__icon md-icon"></span>
            Project
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../project/Reinforcement%20Learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Project 3: Reinforcement Learning
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_6_3" >
        
          
          <label class="md-nav__link" for="__nav_2_6_3" id="__nav_2_6_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Homework
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_6_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_6_3">
            <span class="md-nav__icon md-icon"></span>
            Homework
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../homework/hw1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HW1
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../homework/hw2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HW2
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    论文阅读
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            论文阅读
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../paper_read/virtio-linux-overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    virtio: Towards a De-Facto Standard For Virtual I/O Devices
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../paper_read/SR-IOV_Notes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    High performance network virtualization with SR-IOV
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../paper_read/Performance_Study_10GbE_NICs_SR-IOV/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Evaluating Standard-Based Self-Virtualizing Devices: A Performance Study of 10GbE NICs with SR-IOV Support
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../paper_read/SR-IOV-KVM-Performance-Impact/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Measuring the impact of SR-IOV and virtualization on packet round-trip time
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#non-deterministic-search" class="md-nav__link">
    <span class="md-ellipsis">
      Non-Deterministic Search
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#markov-decision-processes_1" class="md-nav__link">
    <span class="md-ellipsis">
      Markov Decision Processes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Markov Decision Processes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#finite-horizons-and-discounting" class="md-nav__link">
    <span class="md-ellipsis">
      Finite Horizons and Discounting
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#markovianess" class="md-nav__link">
    <span class="md-ellipsis">
      Markovianess
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#solving-markov-decision-processes" class="md-nav__link">
    <span class="md-ellipsis">
      Solving Markov Decision Processes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Solving Markov Decision Processes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-bellman-equation" class="md-nav__link">
    <span class="md-ellipsis">
      The Bellman Equation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#value-iteration" class="md-nav__link">
    <span class="md-ellipsis">
      Value Iteration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#policy-extraction" class="md-nav__link">
    <span class="md-ellipsis">
      Policy Extraction
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#q-value-iteration" class="md-nav__link">
    <span class="md-ellipsis">
      Q-Value Iteration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#policy-iteration" class="md-nav__link">
    <span class="md-ellipsis">
      Policy Iteration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="markov-decision-processes">Markov Decision Processes</h1>
<h2 id="non-deterministic-search">Non-Deterministic Search</h2>
<p>In the first note, we talked about traditional search problems and how to solve them; then, in the third note, we changed our model to account for adversaries and other agents in the world that influenced our path to goal states.</p>
<p>Now, we’ll change our model again to account for another influencing factor – the dynamics of world itself. The environment in which an agent is placed may subject the agent’s actions to being <strong>nondeterministic</strong>, which means that there are multiple possible successor states that can result from an action taken in some state.</p>
<p>Such problems where the world poses a degree of uncertainty are known as <strong>nondeterministic search problems</strong>, and can be solved with models known as <strong>Markov decision processes</strong>, or MDPs.</p>
<h2 id="markov-decision-processes_1">Markov Decision Processes</h2>
<p>A Markov Decision Process is defined by several properties:</p>
<ul>
<li>A set of states <span class="arithmatex">\(S\)</span>. States in MDPs are represented in the same way as states in traditional search problems.</li>
<li>A set of actions <span class="arithmatex">\(A\)</span>. Actions in MDPs are also represented in the same way as in traditional search problems.</li>
<li>A start state.</li>
<li>Possibly one or more terminal states.</li>
<li>Possibly a <strong>discount factor <span class="arithmatex">\(\gamma\)</span>.</strong> </li>
<li>A <strong>transition function</strong> <span class="arithmatex">\(T\left(s, a, s^{\prime}\right)\)</span>. Since we have introduced the possibility of nondeterministic actions, we need a way to delineate the likelihood of the possible outcomes after taking any given action from any given state. The transition function for a MDP does exactly this - it's a probability function which represents the probability that an agent taking an action <span class="arithmatex">\(a \in A\)</span> from a state <span class="arithmatex">\(s \in S\)</span> ends up in a state <span class="arithmatex">\(s^{\prime} \in S\)</span>.</li>
<li>A <strong>reward function</strong> <span class="arithmatex">\(R\left(s, a, s^{\prime}\right)\)</span>. Typically, MDPs are modeled with small "living" rewards at each step to reward an agent's survival, along with large rewards for arriving at a terminal state. Rewards may be positive or negative depending on whether or not they benefit the agent in question, and the agent's objective is naturally to acquire the maximum reward possible before arriving at some terminal state.</li>
</ul>
<p>We represent the movement of an agent through different MDP states over time with discrete <strong>timesteps</strong>, defining <span class="arithmatex">\(s_t \in S\)</span> and <span class="arithmatex">\(a_t \in A\)</span> as the state in which an agent exists and the action which an agent takes at timestep <span class="arithmatex">\(t\)</span> respectively. An agent starts in state <span class="arithmatex">\(s_0\)</span> at timestep 0 , and takes an action at every timestep. The movement of an agent through a MDP can thus be modeled as follows:</p>
<div class="arithmatex">\[
s_0 \xrightarrow{a_0} s_1 \xrightarrow{a_1} s_2 \xrightarrow{a_2} s_3 \xrightarrow{a_3} \ldots
\]</div>
<p>Additionally, knowing that an agent’s goal is to maximize it’s reward across all timesteps, we can correspondingly express this mathematically as a maximization of the following utility function:</p>
<div class="arithmatex">\[
U\left(\left[s_0, a_0, s_1, a_1, s_2, \ldots\right]\right)=R\left(s_0, a_0, s_1\right)+R\left(s_1, a_1, s_2\right)+R\left(s_2, a_2, s_3\right)+\ldots
\]</div>
<p>Markov decision processes, like state-space graphs, can be unraveled into search trees. Uncertainty is modeled in these search trees with <strong>Q-states</strong>, also known as <strong>action states</strong>. The Qstate represented by having taken action <span class="arithmatex">\(a\)</span> from state <span class="arithmatex">\(s\)</span> is notated as the tuple <span class="arithmatex">\((s, a)\)</span>.</p>
<p><img alt="" src="../../img/racecar-tree.png" width="100%" /></p>
<p>The green nodes represent Q-states, where an action has been taken from a state but has yet to be resolved into a successor state.</p>
<h3 id="finite-horizons-and-discounting">Finite Horizons and Discounting</h3>
<p>An MDP enforcing a <strong>finite horizon</strong> is simple - it essentially defines a "lifetime" for agents, which gives them some set number of timesteps <span class="arithmatex">\(n\)</span> to accrue as much reward as they can before being automatically terminated.</p>
<p><strong>Discount factors</strong> are introduced to model an exponential decay in the value of rewards over time. Concretely, with a discount factor of <span class="arithmatex">\(\gamma\)</span>, taking action <span class="arithmatex">\(a_t\)</span> from state <span class="arithmatex">\(s_t\)</span> at timestep <span class="arithmatex">\(t\)</span> and ending up in state <span class="arithmatex">\(s_{t+1}\)</span> results in a reward of <span class="arithmatex">\(\gamma^t R\left(s_t, a_t, s_{t+1}\right)\)</span> instead of just <span class="arithmatex">\(R\left(s_t, a_t, s_{t+1}\right)\)</span>. Now, instead of maximizing the <strong>additive utility</strong></p>
<div class="arithmatex">\[
U\left(\left[s_0, a_0, s_1, a_1, s_2, \ldots\right]\right)=R\left(s_0, a_0, s_1\right)+R\left(s_1, a_1, s_2\right)+R\left(s_2, a_2, s_3\right)+\ldots
\]</div>
<p>we attempt to maximize <strong>discounted utility</strong></p>
<div class="arithmatex">\[
U\left(\left[s_0, a_0, s_1, a_1, s_2, \ldots\right]\right)=R\left(s_0, a_0, s_1\right)+\gamma R\left(s_1, a_1, s_2\right)+\gamma^2 R\left(s_2, a_2, s_3\right)+\ldots
\]</div>
<p>Noting that the above definition of a discounted utility function looks similar to a <strong>geometric series</strong> with ratio <span class="arithmatex">\(\gamma\)</span>, we can prove that it's guaranteed to be finite-valued as long as the constraint <span class="arithmatex">\(|\gamma|&lt;1\)</span> is met :</p>
<div class="arithmatex">\[
\begin{aligned}
U\left(\left[s_0, a_0, s_1, a_1, s_2, \ldots\right]\right) &amp;= R\left(s_0, a_0, s_1\right)+\gamma R\left(s_1, a_1, s_2\right)+\gamma^2 R\left(s_2, a_2, s_3\right)+\ldots \\
&amp;= \sum_{t=0}^{\infty} \gamma^t R\left(s_t, a_t, s_{t+1}\right) \leq \sum_{t=0}^{\infty} \gamma^t R_{\max } = \frac{R_{\max}}{1-\gamma}
\end{aligned}
\]</div>
<h3 id="markovianess">Markovianess</h3>
<p>Markov decision processes are "markovian" in the sense that they satisfy the <strong>Markov property</strong>, or <strong>memoryless property</strong>, which states that the future and the past are conditionally independent, given the present. Intuitively, this means that, if we know the present state, knowing the past doesn’t give us any more information about the future.</p>
<div class="arithmatex">\[
\begin{align*}
P(S_{t+1}=s_{t+1} &amp;\mid S_t=s_t, A_t=a_t, S_{t-1}=s_{t-1}, A_{t-1}=a_{t-1}, \ldots, S_0=s_0) \\
&amp;= P(S_{t+1}=s_{t+1} \mid S_t=s_t, A_t=a_t)
\end{align*}
\]</div>
<p>which is "memoryless" in the sense that <strong>the probability of arriving in a state <span class="arithmatex">\(s^{\prime}\)</span> at time <span class="arithmatex">\(t+1\)</span> depends only on the state <span class="arithmatex">\(s\)</span> and action <span class="arithmatex">\(a\)</span> taken at time <span class="arithmatex">\(t\)</span>, not on any earlier states or actions</strong>. In fact, it is these memoryless probabilities which are encoded by the transition function: <span class="arithmatex">\(T\left(s, a, s^{\prime}\right)=P\left(s^{\prime} \mid s, a\right)\)</span>.</p>
<h2 id="solving-markov-decision-processes">Solving Markov Decision Processes</h2>
<p>Solving a Markov decision process, on the other hand, means finding an optimal <strong>policy <span class="arithmatex">\(\pi^*: S \rightarrow A\)</span></strong>, a function mapping each state <span class="arithmatex">\(s \in S\)</span> to an action <span class="arithmatex">\(a \in A\)</span>. An explicit policy <span class="arithmatex">\(\pi\)</span> defines a reflex agent - given a state <span class="arithmatex">\(s\)</span>, an agent at <span class="arithmatex">\(s\)</span> implementing <span class="arithmatex">\(\pi\)</span> will select <span class="arithmatex">\(a=\pi(s)\)</span> as the appropriate action to make without considering future consequences of its actions. An optimal policy is one that if followed by the implementing agent, will yield the maximum expected total reward or utility.</p>
<h3 id="the-bellman-equation">The Bellman Equation</h3>
<p>We must first introduce two new mathematical quantities:</p>
<ul>
<li>The optimal value of a state <span class="arithmatex">\(s, \  U^*(s) \ \ or \ \  V^*(s)\)</span> - the optimal value of <span class="arithmatex">\(s\)</span> is the expected value of the utility an optimally-behaving agent that starts in <span class="arithmatex">\(s\)</span> will receive, over the rest of the agent's lifetime. </li>
<li>The optimal value of a Q-state <span class="arithmatex">\((s, a), \ Q^*(s, a)\)</span> - the optimal value of <span class="arithmatex">\((s, a)\)</span> is the expected value of the utility an agent receives after starting in <span class="arithmatex">\(s\)</span>, taking <span class="arithmatex">\(a\)</span>, and acting optimally henceforth.</li>
</ul>
<p>Using these two new quantities and the other MDP quantities discussed earlier, the Bellman equation is defined as follows:</p>
<div class="arithmatex">\[
U^*(s)=\max _a \sum_{s^{\prime}} T\left(s, a, s^{\prime}\right)\left[R\left(s, a, s^{\prime}\right)+\gamma U^*\left(s^{\prime}\right)\right]
\]</div>
<p>Before we begin interpreting what this means, let's also define the equation for the optimal value of a Q-state (commonly known as an optimal Q-value):</p>
<div class="arithmatex">\[
Q^*(s, a)=\sum_{s^{\prime}} T\left(s, a, s^{\prime}\right)\left[R\left(s, a, s^{\prime}\right)+\gamma U^*\left(s^{\prime}\right)\right]
\]</div>
<p>This second definition allows us to reexpress the Bellman equation as</p>
<div class="arithmatex">\[
U^*(s)=\max _a Q^*(s, a)
\]</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The Bellman equation is an example of a dynamic programming equation, an equation that decomposes a problem into smaller subproblems via an inherent recursive structure.</p>
</div>
<p>从状态<span class="arithmatex">\(s\)</span>出发，采取action <span class="arithmatex">\(a\)</span>，会有多种可能的successor <span class="arithmatex">\(s'\)</span>,  <span class="arithmatex">\(\left[R\left(s, a, s^{\prime}\right)+\gamma U^*\left(s^{\prime}\right)\right]\)</span> 代表该项表示代理通过首先从<span class="arithmatex">\(s\)</span>采取<span class="arithmatex">\(a\)</span>并到达<span class="arithmatex">\(s'\)</span>，然后在此后采取最佳行动而获得的total utility。
<span class="arithmatex">\(Q^*(s, a)\)</span>对所有可能的<span class="arithmatex">\(s'\)</span>的utility进行加权求和。</p>
<p>从状态<span class="arithmatex">\(s\)</span>开始有多种可能的action <span class="arithmatex">\(a\)</span>，每个action <span class="arithmatex">\(a\)</span>都有对应的<span class="arithmatex">\(Q^*(s, a)\)</span>，<span class="arithmatex">\(U^*(s)\)</span>选择了最大的那个。</p>
<h3 id="value-iteration">Value Iteration</h3>
<p><strong>Value iteration</strong> is a <strong>dynamic programming</strong> algorithm that uses an iteratively longer time limit to compute time-limited values until convergence. It operates as follows:</p>
<ol>
<li><span class="arithmatex">\(\forall s \in S\)</span>, initialize <span class="arithmatex">\(U_0(s)=0\)</span>.</li>
<li>Repeat the following update rule until convergence:</li>
</ol>
<div class="arithmatex">\[
\forall s \in S, U_{k+1}(s) \leftarrow \max _a \sum_{s^{\prime}} T\left(s, a, s^{\prime}\right)\left[R\left(s, a, s^{\prime}\right)+\gamma U_k\left(s^{\prime}\right)\right]
\]</div>
<p>For conciseness, we frequently denote <span class="arithmatex">\(U_{k+1}(s) \leftarrow \max _a \sum_{s^{\prime}} T\left(s, a, s^{\prime}\right)\left[R\left(s, a, s^{\prime}\right)+\gamma U_k\left(s^{\prime}\right)\right]\)</span> with the shorthand <span class="arithmatex">\(U_{k+1} \leftarrow B U_k\)</span>, where <span class="arithmatex">\(B\)</span> is called the Bellman operator. </p>
<h3 id="policy-extraction">Policy Extraction</h3>
<p>Recall that our ultimate goal in solving a MDP is to determine an optimal policy. This can be done once all optimal values for states are determined using a method called <strong>policy extraction</strong>. The intuition behind policy extraction is very simple: if you're in a state <span class="arithmatex">\(s\)</span>, you should take the action <span class="arithmatex">\(a\)</span> which yields the maximum expected utility.</p>
<div class="arithmatex">\[
\forall s \in S, \pi^*(s)=\underset{a}{\operatorname{argmax}} Q^*(s, a)=\underset{a}{\operatorname{argmax}} \sum_{s^{\prime}} T\left(s, a, s^{\prime}\right)\left[R\left(s, a, s^{\prime}\right)+\gamma U^*\left(s^{\prime}\right)\right]
\]</div>
<h3 id="q-value-iteration">Q-Value Iteration</h3>
<p><strong>Q-value iteration</strong> is a dynamic programming algorithm that computes time-limited Q-values. It is described in the following equation:</p>
<div class="arithmatex">\[
Q_{k+1}(s, a) \leftarrow \sum_{s^{\prime}} T\left(s, a, s^{\prime}\right)\left[R\left(s, a, s^{\prime}\right)+\gamma \max _{a^{\prime}} Q_k\left(s^{\prime}, a^{\prime}\right)\right]
\]</div>
<p>Once we have the optimal Q-values for each state and action, we can then find the policy for a state by simply choosing the action which has the highest Q-value.</p>
<h3 id="policy-iteration">Policy Iteration</h3>
<p><strong>Policy iteration</strong>: an algorithm that maintains the optimality of value iteration while providing significant performance gains. </p>
<ol>
<li>Define an <em>initial policy</em>. This can be arbitrary, but policy iteration will converge faster the closer the initial policy is to the eventual optimal policy.</li>
<li>Repeat the following until convergence:</li>
</ol>
<div class="admonition tip">
<ul>
<li>Evaluate the current policy with <strong>policy evaluation</strong>. For a policy <span class="arithmatex">\(\pi\)</span>, policy evaluation means computing <span class="arithmatex">\(U^\pi(s)\)</span> for all states <span class="arithmatex">\(s\)</span>, where <span class="arithmatex">\(U^\pi(s)\)</span> is expected utility of starting in state <span class="arithmatex">\(s\)</span> when following <span class="arithmatex">\(\pi\)</span> :</li>
</ul>
<div class="arithmatex">\[
U^\pi(s)=\sum_{s^{\prime}} T\left(s, \pi(s), s^{\prime}\right)\left[R\left(s, \pi(s), s^{\prime}\right)+\gamma U^\pi\left(s^{\prime}\right)\right]
\]</div>
<p>Define the policy at iteration <span class="arithmatex">\(i\)</span> of policy iteration as <span class="arithmatex">\(\pi_i\)</span>. Since we are fixing a single action for each state, we no longer need the max operator which effectively leaves us with a system of <span class="arithmatex">\(|S|\)</span> equations generated by the above rule. Each <span class="arithmatex">\(U^{\pi_i}(s)\)</span> can then be computed by simply solving this system. Alternatively, we can also compute <span class="arithmatex">\(U^{\pi_i}(s)\)</span> by using the following update rule until convergence, just like in value iteration:
$$
U_{k+1}^{\pi_i}(s) \leftarrow \sum_{s^{\prime}} T\left(s, \pi_i(s), s^{\prime}\right)\left[R\left(s, \pi_i(s), s^{\prime}\right)+\gamma U_k^{\pi_i}\left(s^{\prime}\right)\right]
$$</p>
<p>However, this second method is typically slower in practice.</p>
<ul>
<li>Once we've evaluated the current policy, use <strong>policy improvement</strong> to generate a better policy. Policy improvement uses policy extraction on the values of states generated by policy evaluation to generate this new and improved policy:</li>
</ul>
<div class="arithmatex">\[
\pi_{i+1}(s)=\underset{a}{\operatorname{argmax}} \sum_{s^{\prime}} T\left(s, a, s^{\prime}\right)\left[R\left(s, a, s^{\prime}\right)+\gamma U^{\pi_i}\left(s^{\prime}\right)\right]
\]</div>
<p>If <span class="arithmatex">\(\pi_{i+1}=\pi_i\)</span>, the algorithm has converged, </p>
<p>and we can conclude that <span class="arithmatex">\(\pi_{i+1}=\pi_i=\pi^*\)</span>.</p>
</div>
<h3 id="summary">Summary</h3>
<ul>
<li><em>Value iteration</em>: Used for computing the optimal values of states, by iterative updates until convergence.</li>
<li><em>Policy evaluation</em>: Used for computing the values of states under a specific policy.</li>
<li><em>Policy extraction</em>: Used for determining a policy given some state value function. If the state values are optimal, this policy will be optimal. This method is used after running value iteration, to compute an optimal policy from the optimal state values; or as a subroutine in policy iteration, to compute the best policy for the currently estimated state values.</li>
<li><em>Policy iteration</em>: A technique that encapsulates both policy evaluation and policy extraction and is used for iterative convergence to an optimal policy. It tends to outperform value iteration, by virtue of the fact that policies usually converge much faster than the values of states.</li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": ["content.code.select"], "search": "../../../../assets/javascripts/workers/search.07f07601.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.56dfad97.min.js"></script>
      
        <script src="../../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>